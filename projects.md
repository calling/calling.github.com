---
layout: default
title: "Projects"
---

<h3>Personal</h3>
<dl>
	<dt><a href="//github.com/calling/calling.github.com">This website</a></dt>
	<dd>Powered by Jekyll and Jekyll-Bootstrap on Github pages</dd>
	<dt><a href="//njaumc.github.com">NJAUMC camp website</a></dt>
	<dd>Powered by Jekyll on Github pages. Built design (HTML/CSS/JQuery) with Twitter Bootstrap. You can check out the code on <a href="//github.com/njaumc/njaumc.github.com">Github</a>.</dd>
</dl>

<h3>Spring 2013</h3>
<dl>
	<dt><a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-28.html">Sauron: Embedded Single-Camera Sensing of Printed Physical User Interfaces (Second Author)</a></dt>
	<dd>3D printers enable designers to rapidly produce working models of future products. Today these physical prototypes are mostly passive. Our research goal is to enable designers to turn models produced on commodity 3D printers into interactive objects with a minimum of required assembly or instrumentation. We present Sauron, an embedded machine vision-based system for sensing human input on physical controls like buttons, sliders, and joysticks. With Sauron, designers attach a single camera with integrated ring light to a printed prototype. This camera observes the interior portions of input components to determine their actuation and position. In many prototypes, input components may be occluded or outside the viewing frustum of a single camera. We introduce algorithms that generate internal geometry and calculate mirror placements to redirect input motion into the visible camera area. To investigate the space of designs that can be built with Sauron along with its limitations, we built prototype devices, evaluated the suitability of existing models for vision sensing, and performed an informal study with 3 CAD users. While our approach imposes some constraints on device design, results suggest that it is expressive and accessible enough to enable constructing a useful variety of devices.</dd>
	<dt><a href="http://husk.eecs.berkeley.edu/courses/cs160-sp13/index.php/Group:%E2%98%83">Betternote: an Android App by â˜ƒ</a></dt>
	<dd>Features an infinitely zoomable canvas to create and organize ideas. Created using the <a href="http://en.wikipedia.org/wiki/User-centered_design">User Centered Design Cycle</a></dd>
	<dt><a href="http://husk.eecs.berkeley.edu/courses/cs160-sp13/index.php/ProgrammingAssignment3-Colin_Chang">aBart: Android App for new Bart users</a></dt>
	<dt><a href="http://husk.eecs.berkeley.edu/courses/cs160-sp13/index.php/ProgrammingAssignment2-Colin_Chang">Paper: Android finger drawing application</a></dt>
</dl>
<h3>Fall 2012</h3>
<dl class="inline>">
	<dt><a href="http://www-inst.eecs.berkeley.edu/~cs162/fa12/Nachos/phase1.html">Operating Systems: Threading</a></dt>
	<dt><a href="http://www-inst.eecs.berkeley.edu/~cs162/fa12/Nachos/phase2.html">Operating Systems: Multiprogramming</a></dt>
	<dt><a href="http://www-inst.eecs.berkeley.edu/~cs162/fa12/phase3.html">Operating Systems: Single Server Key-Value Store</a></dt>
	<dt><a href="http://www-inst.eecs.berkeley.edu/~cs162/fa12/phase4.html">Operating Systems: Distributed Key-Value Store</a></dt>
	
	<dt><a href="https://github.com/cs186-fa12/fa12/blob/master/hw2/README.md">Database Systems: loCALee - Database Schema Design and Web Application Server Code in Ruby On Rails</a></dt>
	<dt><a href="https://github.com/cs186-fa12/fa12/blob/master/hw3/README.md">Database Systems: Buffer Management in PostgreSQL</a></dt>
	<dt><a href="https://github.com/cs186-fa12/fa12/blob/master/hw5/README.md">Database Systems: Approximate Top-K using Count-Min Sketch</a></dt>

	<dt>Artificial Intelligence: Search in Pacman</dt>
	<dd>In this project, your Pacman agent will find paths through his maze world, both to reach a particular location and to collect food efficiently. You will build general search algorithms and apply them to Pacman scenarios.</dd>
	<dt>Artificial Intelligence: Multi-Agent Pacman</dt>
	<dd>In this project, you will design agents for the classic version of Pacman, including ghosts. Along the way, you will implement both minimax and expectimax search and try your hand at evaluation function design.</dd>
	<dt>Artificial Intelligence: Reinforcement Learning</dt>
	<dd>In this project, you will implement value iteration and Q-learning. You will test your agents first on Gridworld (from class), then apply them to a simulated robot controller (Crawler) and Pacman.</dd>
	<dt>Artificial Intelligence: Ghostbuster</dt>
	<dd>In this project, you will design Pacman agents that use sensors to locate and eat invisible ghosts. You'll advance from locating single, stationary ghosts to hunting packs of multiple moving ghosts with ruthless efficiency.</dd>
	<dt>Artificial Intelligence: Classification</dt>
	<dd>In this project, you will design three classifiers: a naive Bayes classifier, a perceptron classifier and a large-margin (MIRA) classifier. You will test your classifiers on two image data sets: a set of scanned handwritten digit images and a set of face images in which edges have already been detected. Even with simple features, your classifiers will be able to do quite well on these tasks when given enough training data.</dd>
</dl>